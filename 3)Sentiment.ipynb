{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7905738d-7f02-4772-8f4b-484281ed4ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'llama3.1:8b',\n",
       "   'model': 'llama3.1:8b',\n",
       "   'modified_at': '2024-11-06T15:34:28.326803983+09:00',\n",
       "   'size': 4661230766,\n",
       "   'digest': '42182419e9508c30c4b1fe55015f06b65f4ca4b9e28a744be55008d21998a093',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'gemma2:27b',\n",
       "   'model': 'gemma2:27b',\n",
       "   'modified_at': '2024-11-05T19:58:30.214524333+09:00',\n",
       "   'size': 15628387458,\n",
       "   'digest': '53261bc9c192c1cb5fcc898dd3aa15da093f5ab6f08e17e48cf838bb1c58abfe',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'gemma2',\n",
       "    'families': ['gemma2'],\n",
       "    'parameter_size': '27.2B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'mistral:7b',\n",
       "   'model': 'mistral:7b',\n",
       "   'modified_at': '2024-11-05T19:34:44.773585762+09:00',\n",
       "   'size': 4113301824,\n",
       "   'digest': 'f974a74358d62a017b37c6f424fcdf2744ca02926c4f952513ddf474b2fa5091',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '7.2B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3.2:3b',\n",
       "   'model': 'llama3.2:3b',\n",
       "   'modified_at': '2024-11-05T19:16:35.326885773+09:00',\n",
       "   'size': 2019393189,\n",
       "   'digest': 'a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '3.2B',\n",
       "    'quantization_level': 'Q4_K_M'}}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# 풀할 모델 리스트\n",
    "models_to_pull = [\n",
    "    \"llama3.1:8b\",\n",
    "    \"gemma2:27b\",\n",
    "    \"mistral:7b\",\n",
    "    \"llama3.2:3b\"\n",
    "]\n",
    "\n",
    "# 모델 풀하기\n",
    "for model_name in models_to_pull:\n",
    "    print(f\"Pulling model: {model_name}\")\n",
    "    ollama.pull(model_name)\n",
    "\n",
    "print(\"Selected models have been pulled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e6ff90-dd87-4059-b3dd-c1b4af34b013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 모델 이름 리스트 자동으로 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    # Define the keywords\n",
    "    keywords = [\"positive\", \"negative\", \"neutral\"]\n",
    "    # Convert text to lowercase and find the earliest occurrence of any keyword\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # Find the keyword with the smallest index that is not -1\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    # Default to 'neutral' if no keyword is found\n",
    "    return \"neutral\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    # 모델별 CSV 파일 경로 설정\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    output_csv = os.path.join(output_folder, f'{sanitized_model_name}_NOCoT.csv')\n",
    "    \n",
    "    # Load or create the CSV data\n",
    "    if os.path.exists(output_csv):\n",
    "        news_data = pd.read_csv(output_csv)\n",
    "    else:\n",
    "        news_data = pd.read_csv(input_csv)\n",
    "        news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "    # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "            # Define the system message to set the role\n",
    "            system_message = {\n",
    "                'role': 'system',\n",
    "                'content': \"You are a stock analyst specializing in assessing sentiment in financial news articles.\"\n",
    "            }\n",
    "\n",
    "            # Define the question based on the article title and provide the response format\n",
    "            question = f\"Based on the article titled '{row['Title']}' determine if the tone is positive, negative, or neutral toward {row['Symbol']}.\\n\" \\\n",
    "           \"Please respond in the following format, and omit any reasoning:\\n\" \\\n",
    "           \"Sentiment: [positive/negative/neutral]\"\n",
    "\n",
    "            # Send the question to the model\n",
    "            response = ollama.chat(model=model_name, messages=[\n",
    "                system_message,\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': question,\n",
    "                },\n",
    "            ])\n",
    "\n",
    "            # Extract the response content\n",
    "            sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"No response\"\n",
    "\n",
    "            # Update the sentiment analysis directly in the DataFrame\n",
    "            news_data.at[index, 'Sentiment Analysis'] = sentiment_response\n",
    "\n",
    "            # Save the DataFrame back to CSV after each response\n",
    "            news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    # Apply the sentiment extraction function to create the Predict column\n",
    "    news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "\n",
    "    # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "    news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a77af8-58a2-47ec-ab5c-75dc7f0ddf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 모델 이름 리스트 자동으로 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "# 감정 추출 함수\n",
    "def extract_sentiment(text):\n",
    "    # Define the keywords\n",
    "    keywords = [\"positive\", \"negative\", \"neutral\"]\n",
    "    # Convert text to lowercase and find the earliest occurrence of any keyword\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # Find the keyword with the smallest index that is not -1\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    # Default to 'neutral' if no keyword is found\n",
    "    return \"neutral\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    # 모델별 CSV 파일 경로 설정\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    output_csv = os.path.join(output_folder, f'{sanitized_model_name}_CoT.csv')\n",
    "    \n",
    "    # Load or create the CSV data\n",
    "    if os.path.exists(output_csv):\n",
    "        news_data = pd.read_csv(output_csv)\n",
    "    else:\n",
    "        news_data = pd.read_csv(input_csv)\n",
    "        news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "    # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "            # Define the system message to set the role\n",
    "            system_message = {\n",
    "                'role': 'system',\n",
    "                'content': \"You are a stock analyst specializing in assessing sentiment in financial news articles.\"\n",
    "            }\n",
    "\n",
    "            # Define the question based on the article title and provide the response format\n",
    "            question = f\"Based on the article titled '{row['Title']}' determine if the tone is positive, negative, or neutral toward {row['Symbol']}.\\n\" \\\n",
    "                       \"Please respond in the following format:\\n\" \\\n",
    "                       \"Sentiment: [positive/negative/neutral]\\n\" \\\n",
    "                       \"Reason: [Brief explanation based on the article]\"\n",
    "\n",
    "            # Send the question to the model\n",
    "            response = ollama.chat(model=model_name, messages=[\n",
    "                system_message,\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': question,\n",
    "                },\n",
    "            ])\n",
    "\n",
    "            # Extract the response content\n",
    "            sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"No response\"\n",
    "\n",
    "            # Update the sentiment analysis directly in the DataFrame\n",
    "            news_data.at[index, 'Sentiment Analysis'] = sentiment_response\n",
    "\n",
    "            # Save the DataFrame back to CSV after each response\n",
    "            news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    # Apply the sentiment extraction function to create the Predict column\n",
    "    news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "\n",
    "    # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "    news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541c3c6e-8a76-4b08-b669-5bae09aedd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 모델 이름 리스트 자동으로 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "# 감정 추출 함수\n",
    "def extract_sentiment(text):\n",
    "    # Define the keywords\n",
    "    keywords = [\"positive\", \"negative\", \"neutral\"]\n",
    "    # Convert text to lowercase and find the earliest occurrence of any keyword\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # Find the keyword with the smallest index that is not -1\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    # Default to 'neutral' if no keyword is found\n",
    "    return \"neutral\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    output_csv = os.path.join(output_folder, f'{sanitized_model_name}_Bootstrap.csv')\n",
    "    \n",
    "    if os.path.exists(output_csv):\n",
    "        news_data = pd.read_csv(output_csv)\n",
    "    else:\n",
    "        news_data = pd.read_csv(input_csv)\n",
    "        news_data['Sentiment Analysis'] = None\n",
    "\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "            responses = []\n",
    "            for _ in range(5):  # 5번 반복하여 모델에 요청\n",
    "                system_message = {\n",
    "                    'role': 'system',\n",
    "                    'content': \"You are a stock analyst specializing in assessing sentiment in financial news articles.\"\n",
    "                }\n",
    "                question = f\"Based on the article titled '{row['Title']}' determine if the tone is positive, negative, or neutral toward {row['Symbol']}.\\n\" \\\n",
    "                           \"Please respond in the following format, and omit any reasoning:\\n\" \\\n",
    "                           \"Sentiment: [positive/negative/neutral]\"\n",
    "\n",
    "                response = ollama.chat(model=model_name, messages=[\n",
    "                    system_message,\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': question,\n",
    "                    },\n",
    "                ])\n",
    "                \n",
    "                sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"neutral\"\n",
    "                responses.append(extract_sentiment(sentiment_response))\n",
    "\n",
    "            # 가장 많이 등장한 응답이 3번 이상일 경우 그 응답을 사용\n",
    "            response_counts = Counter(responses)\n",
    "            most_common_response, count = response_counts.most_common(1)[0]\n",
    "            if count >= 3:\n",
    "                final_sentiment = most_common_response\n",
    "            else:\n",
    "                final_sentiment = \"neutral\"\n",
    "\n",
    "            news_data.at[index, 'Sentiment Analysis'] = final_sentiment\n",
    "\n",
    "            # CSV에 저장\n",
    "            news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "    news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "    news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f509f4f2-ead1-44ab-84af-b1a042f2aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 데이터에 대해 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# BERT 기반 감정 분석 파이프라인 초기화\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# 감정 레이블을 Positive/Negative/Neutral로 매핑\n",
    "def map_label_to_sentiment(label):\n",
    "    label_mapping = {\n",
    "        \"1 star\": \"negative\",\n",
    "        \"2 stars\": \"negative\",\n",
    "        \"3 stars\": \"neutral\",\n",
    "        \"4 stars\": \"positive\",\n",
    "        \"5 stars\": \"positive\"\n",
    "    }\n",
    "    return label_mapping.get(label, \"neutral\")\n",
    "\n",
    "# 감정 분석 수행\n",
    "output_csv = os.path.join(output_folder, 'BERT.csv')\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    news_data = pd.read_csv(output_csv)\n",
    "else:\n",
    "    news_data = pd.read_csv(input_csv)\n",
    "    news_data['Predict'] = None  # 'Predict' 열로 변경\n",
    "\n",
    "for index, row in news_data.iterrows():\n",
    "    if pd.isna(row['Predict']):  # 감정 분석 결과가 없는 경우\n",
    "        text_to_analyze = row['Title']  # Title만 분석\n",
    "        response_label = sentiment_pipeline(text_to_analyze)[0]['label']  # 감정 레이블 ('1 star', '2 stars', etc.)\n",
    "        sentiment = map_label_to_sentiment(response_label)\n",
    "\n",
    "        # 감정 분석 결과 저장\n",
    "        news_data.at[index, 'Predict'] = sentiment  # 'Predict' 열에 저장\n",
    "\n",
    "        # CSV에 저장\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 데이터에 대해 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41478fc7-ba46-4c46-976b-f667da19b179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 데이터에 대해 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# FinBERT 모델 및 토크나이저 초기화\n",
    "finbert_model_name = \"yiyanghkust/finbert-tone\"  # FinBERT 모델 이름\n",
    "tokenizer = AutoTokenizer.from_pretrained(finbert_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finbert_model_name)\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 감정 분석 수행\n",
    "output_csv = os.path.join(output_folder, 'FinBERT.csv')\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    news_data = pd.read_csv(output_csv)\n",
    "else:\n",
    "    news_data = pd.read_csv(input_csv)\n",
    "    news_data['Predict'] = None  # 'Predict' 열로 변경\n",
    "\n",
    "for index, row in news_data.iterrows():\n",
    "    if pd.isna(row['Predict']):  # 감정 분석 결과가 없는 경우\n",
    "        text_to_analyze = row['Title']  # Title만 분석\n",
    "        response = sentiment_pipeline(text_to_analyze)[0]['label'].lower()  # 'positive', 'negative', 'neutral'\n",
    "\n",
    "        # 감정 분석 결과 저장\n",
    "        news_data.at[index, 'Predict'] = response\n",
    "\n",
    "        # CSV에 저장\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 데이터에 대해 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ccbf16-32f5-4283-97c2-8d76c6e60d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 데이터에 대해 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# RoBERTa-Finance 모델 초기화\n",
    "roberta_model_name = \"soleimanian/financial-roberta-large-sentiment\"  # RoBERTa-Finance 모델 이름\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta_model_name)\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 감정 분석 수행\n",
    "output_csv = os.path.join(output_folder, 'RoBERTaFinance.csv')\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    news_data = pd.read_csv(output_csv)\n",
    "else:\n",
    "    news_data = pd.read_csv(input_csv)\n",
    "    news_data['Predict'] = None  # 'Predict' 열로 변경\n",
    "\n",
    "for index, row in news_data.iterrows():\n",
    "    if pd.isna(row['Predict']):  # 감정 분석 결과가 없는 경우\n",
    "        text_to_analyze = row['Title']  # Title만 분석\n",
    "        response = sentiment_pipeline(text_to_analyze)[0]['label'].lower()  # 'positive', 'negative', 'neutral'\n",
    "\n",
    "        # 감정 분석 결과 저장\n",
    "        news_data.at[index, 'Predict'] = response\n",
    "\n",
    "        # CSV에 저장\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 데이터에 대해 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d302ef8-73cc-4fd9-84e6-c98e71e4451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 참조할 모델별 CSV 파일 로드\n",
    "reference_models = [\"BERT\", \"FinBERT\", \"RoBERTaFinance\"]\n",
    "reference_data = {}\n",
    "\n",
    "for ref_model in reference_models:\n",
    "    ref_path = os.path.join(output_folder, f\"{ref_model}.csv\")\n",
    "    if os.path.exists(ref_path):\n",
    "        reference_data[ref_model] = pd.read_csv(ref_path)\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    # Define the keywords\n",
    "    keywords = [\"positive\", \"negative\", \"neutral\"]\n",
    "    # Convert text to lowercase and find the earliest occurrence of any keyword\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # Find the keyword with the smallest index that is not -1\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    # Default to 'neutral' if no keyword is found\n",
    "    return \"neutral\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "for model_name in models:\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    \n",
    "    for ref_model, ref_df in reference_data.items():\n",
    "        # 모델별, 참조모델별 CSV 파일 경로 설정\n",
    "        output_csv = os.path.join(output_folder, f'{sanitized_model_name}_{ref_model}-ICL.csv')\n",
    "        \n",
    "        # Load or create the CSV data\n",
    "        if os.path.exists(output_csv):\n",
    "            news_data = pd.read_csv(output_csv)\n",
    "        else:\n",
    "            news_data = pd.read_csv(input_csv)\n",
    "            news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "        # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "        for index, row in news_data.iterrows():\n",
    "            if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "                # 참조 모델의 Predict 값 가져오기\n",
    "                ref_predict = None\n",
    "                ref_row = ref_df[ref_df['Title'] == row['Title']]\n",
    "                if not ref_row.empty:\n",
    "                    ref_predict = ref_row.iloc[0]['Predict']\n",
    "\n",
    "                # Define the system message to set the role\n",
    "                system_message = {\n",
    "                    'role': 'system',\n",
    "                    'content': \"You are a stock analyst specializing in assessing sentiment in financial news articles.\"\n",
    "                }\n",
    "\n",
    "                # Define the question based on the article title and reference model prediction\n",
    "                question = f\"Based on the article titled '{row['Title']}', determine if the tone is positive, negative, or neutral toward {row['Symbol']}.\\n\" \\\n",
    "                           f\"The sentiment prediction from {ref_model} is '{ref_predict}'.\\n\" \\\n",
    "                           \"Please respond in the following format, and omit any reasoning:\\n\" \\\n",
    "                           \"If your sentiment differs from the reference prediction, provide a brief reason why:\\n\" \\\n",
    "                           \"Sentiment: [positive/negative/neutral]\\nReason: [Provide reason only if your sentiment differs from the reference]\"\n",
    "\n",
    "                # Send the question to the model\n",
    "                response = ollama.chat(model=model_name, messages=[\n",
    "                    system_message,\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': question,\n",
    "                    },\n",
    "                ])\n",
    "\n",
    "                # Extract the response content\n",
    "                sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"No response\"\n",
    "\n",
    "                # Update the sentiment analysis directly in the DataFrame\n",
    "                news_data.at[index, 'Sentiment Analysis'] = sentiment_response\n",
    "\n",
    "                # Save the DataFrame back to CSV after each response\n",
    "                news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "        # Apply the sentiment extraction function to create the Predict column\n",
    "        news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "\n",
    "        # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b27f9293-a197-4176-9423-f737ce65a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "from collections import Counter\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 참조할 모델별 CSV 파일 로드\n",
    "reference_models = [\"BERT\", \"FinBERT\", \"RoBERTaFinance\"]\n",
    "reference_data = {}\n",
    "\n",
    "for ref_model in reference_models:\n",
    "    ref_path = os.path.join(output_folder, f\"{ref_model}.csv\")\n",
    "    if os.path.exists(ref_path):\n",
    "        reference_data[ref_model] = pd.read_csv(ref_path)\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    # Define the keywords\n",
    "    keywords = [\"positive\", \"negative\", \"neutral\"]\n",
    "    # Convert text to lowercase and find the earliest occurrence of any keyword\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # Find the keyword with the smallest index that is not -1\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    # Default to 'neutral' if no keyword is found\n",
    "    return \"neutral\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "for model_name in models:\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    \n",
    "    for ref_model, ref_df in reference_data.items():\n",
    "        # 모델별, 참조모델별 CSV 파일 경로 설정\n",
    "        output_csv = os.path.join(output_folder, f'{sanitized_model_name}_{ref_model}-BOOTICL.csv')\n",
    "        \n",
    "        # Load or create the CSV data\n",
    "        if os.path.exists(output_csv):\n",
    "            news_data = pd.read_csv(output_csv)\n",
    "        else:\n",
    "            news_data = pd.read_csv(input_csv)\n",
    "            news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "        # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "        for index, row in news_data.iterrows():\n",
    "            if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "                sentiments = []\n",
    "                for _ in range(5):  # Repeat 5 times\n",
    "                    # 참조 모델의 Predict 값 가져오기\n",
    "                    ref_predict = None\n",
    "                    ref_row = ref_df[ref_df['Title'] == row['Title']]\n",
    "                    if not ref_row.empty:\n",
    "                        ref_predict = ref_row.iloc[0]['Predict']\n",
    "\n",
    "                    # Define the system message to set the role\n",
    "                    system_message = {\n",
    "                        'role': 'system',\n",
    "                        'content': \"You are a stock analyst specializing in assessing sentiment in financial news articles.\"\n",
    "                    }\n",
    "\n",
    "                    # Define the question based on the article title and reference model prediction\n",
    "                    question = f\"Based on the article titled '{row['Title']}', determine if the tone is positive, negative, or neutral toward {row['Symbol']}.\\n\" \\\n",
    "                               f\"The sentiment prediction from {ref_model} is '{ref_predict}'.\\n\" \\\n",
    "                               \"Please respond in the following format, and omit any reasoning:\\n\" \\\n",
    "                               \"Sentiment: [positive/negative/neutral]\"\n",
    "\n",
    "                    # Send the question to the model\n",
    "                    response = ollama.chat(model=model_name, messages=[\n",
    "                        system_message,\n",
    "                        {\n",
    "                            'role': 'user',\n",
    "                            'content': question,\n",
    "                        },\n",
    "                    ])\n",
    "\n",
    "                    # Extract the response content\n",
    "                    sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"neutral\"\n",
    "                    sentiment = extract_sentiment(sentiment_response)\n",
    "                    sentiments.append(sentiment)\n",
    "\n",
    "                # Determine the majority sentiment or default to 'neutral'\n",
    "                sentiment_count = Counter(sentiments)\n",
    "                majority_sentiment, count = sentiment_count.most_common(1)[0]\n",
    "                if count >= 3:  # Majority rule\n",
    "                    final_sentiment = majority_sentiment\n",
    "                else:\n",
    "                    final_sentiment = \"neutral\"\n",
    "\n",
    "                # Update the sentiment analysis directly in the DataFrame\n",
    "                news_data.at[index, 'Sentiment Analysis'] = final_sentiment\n",
    "\n",
    "                # Save the DataFrame back to CSV after each response\n",
    "                news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "        # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "        news_data['Predict'] = news_data['Sentiment Analysis']\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a926abf-4cfc-4607-89a3-d59bdcab13ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
