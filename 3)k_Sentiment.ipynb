{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe45898-f3d1-4717-8691-37078820f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# 풀할 모델 리스트\n",
    "models_to_pull = [\n",
    "    \"llama3.1:8b\",\n",
    "    \"gemma2:27b\",\n",
    "    \"mistral:7b\",\n",
    "    \"llama3.2:3b\"\n",
    "]\n",
    "\n",
    "# 모델 풀하기\n",
    "for model_name in models_to_pull:\n",
    "    print(f\"Pulling model: {model_name}\")\n",
    "    ollama.pull(model_name)\n",
    "\n",
    "print(\"Selected models have been pulled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8666e0d-5df7-475c-ad45-f06aee1e67cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_NOCoT.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: gemma2:27b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/gemma2_27b_NOCoT.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/mistral_7b_NOCoT.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_NOCoT.csv'에 저장되었습니다.\n",
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 모델 이름 리스트 자동으로 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    keywords = [\"긍정\", \"부정\", \"중립\"]\n",
    "    # 텍스트를 소문자로 변환하고 키워드가 가장 먼저 등장하는 순서를 판별\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # 등장한 키워드 중 가장 빠른 순서의 키워드 반환 (등장하지 않으면 기본값 '중립')\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    return \"중립\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    # 모델별 CSV 파일 경로 설정 (특수 문자 대체)\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    output_csv = os.path.join(output_folder, f'{sanitized_model_name}_NOCoT.csv')\n",
    "    \n",
    "    # Load or create the DataFrame\n",
    "    if os.path.exists(output_csv):\n",
    "        news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "    else:\n",
    "        news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "        news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "    # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "            # Define the system message to set the role\n",
    "            system_message = {\n",
    "                'role': 'system',\n",
    "                'content': \"당신은 금융 뉴스 기사에서 감정을 평가하는 주식 분석가입니다.\"\n",
    "            }\n",
    "\n",
    "            # Define the question based on the article title and provide the response format\n",
    "            question = f\"'{row['Title']}' 제목의 {row['Company']}에 대한 톤이 긍정적, 부정적 또는 중립적인지 결정하십시오.\\n\" \\\n",
    "                       \"다음 형식으로 응답해 주세요. 이유는 생략합니다:\\n\" \\\n",
    "                       \"Sentiment: [긍정/부정/중립]\"\n",
    "\n",
    "            # Send the question to the model\n",
    "            response = ollama.chat(model=model_name, messages=[\n",
    "                system_message,\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': question,\n",
    "                },\n",
    "            ])\n",
    "\n",
    "            # Extract the response content\n",
    "            sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"No response\"\n",
    "\n",
    "            # Update the sentiment analysis directly in the DataFrame\n",
    "            news_data.at[index, 'Sentiment Analysis'] = sentiment_response\n",
    "\n",
    "            # Save the DataFrame back to CSV after each response\n",
    "            news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Apply the sentiment extraction function to create the Predict column\n",
    "    news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "    \n",
    "    # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "    news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839c18a8-ecd0-4501-8132-0e1f8588811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_CoT.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: gemma2:27b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/gemma2_27b_CoT.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/mistral_7b_CoT.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_CoT.csv'에 저장되었습니다.\n",
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 모델 이름 리스트 자동으로 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    keywords = [\"긍정\", \"부정\", \"중립\"]\n",
    "    # 텍스트를 소문자로 변환하고 키워드가 가장 먼저 등장하는 순서를 판별\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    # 등장한 키워드 중 가장 빠른 순서의 키워드 반환 (등장하지 않으면 기본값 '중립')\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    return \"중립\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    # 모델별 CSV 파일 경로 설정 (특수 문자 대체)\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    output_csv = os.path.join(output_folder, f'{sanitized_model_name}_CoT.csv')\n",
    "    \n",
    "    # Load or create the DataFrame\n",
    "    if os.path.exists(output_csv):\n",
    "        news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "    else:\n",
    "        news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "        news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "    # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "            # Define the system message to set the role\n",
    "            system_message = {\n",
    "                'role': 'system',\n",
    "                'content': \"당신은 금융 뉴스 기사에서 감정을 평가하는 주식 분석가입니다.\"\n",
    "            }\n",
    "\n",
    "            # Define the question based on the article title and provide the response format\n",
    "            question = f\"'{row['Title']}' 제목의 {row['Company']}에 대한 톤이 긍정적, 부정적 또는 중립적인지 결정하십시오.\\n\" \\\n",
    "                       \"다음 형식으로 응답해 주세요.:\\n\" \\\n",
    "                       \"Sentiment: [긍정/부정/중립]\\n\" \\\n",
    "                       \"Reason: [기사를 기반으로 한 간략한 설명]\"\n",
    "\n",
    "            # Send the question to the model\n",
    "            response = ollama.chat(model=model_name, messages=[\n",
    "                system_message,\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': question,\n",
    "                },\n",
    "            ])\n",
    "\n",
    "            # Extract the response content\n",
    "            sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"No response\"\n",
    "\n",
    "            # Update the sentiment analysis directly in the DataFrame\n",
    "            news_data.at[index, 'Sentiment Analysis'] = sentiment_response\n",
    "\n",
    "            # Save the DataFrame back to CSV after each response\n",
    "            news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Apply the sentiment extraction function to create the Predict column\n",
    "    news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "    \n",
    "    # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "    news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1e4a5b-81ff-4525-b865-d1949b6cc393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_Bootstrap.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: gemma2:27b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/gemma2_27b_Bootstrap.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/mistral_7b_Bootstrap.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_Bootstrap.csv'에 저장되었습니다.\n",
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# 모델 이름 리스트 자동으로 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    keywords = [\"긍정\", \"부정\", \"중립\"]\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    return \"중립\"\n",
    "\n",
    "def majority_vote(sentiments):\n",
    "    \"\"\"\n",
    "    Determine the final sentiment based on majority voting.\n",
    "    If no sentiment appears at least 3 times, return '중립'.\n",
    "    \"\"\"\n",
    "    sentiment_counts = Counter(sentiments)\n",
    "    for sentiment, count in sentiment_counts.items():\n",
    "        if count >= 3:\n",
    "            return sentiment\n",
    "    return \"중립\"\n",
    "\n",
    "# 각 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    output_csv = os.path.join(output_folder, f'{sanitized_model_name}_Bootstrap.csv')\n",
    "    \n",
    "    if os.path.exists(output_csv):\n",
    "        news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "    else:\n",
    "        news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "        news_data['Sentiment Analysis'] = None  # Initialize for 5 repetitions\n",
    "        news_data['Predict'] = None  # Initialize final prediction column\n",
    "\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Predict']):  # Skip if already processed\n",
    "            sentiments = []\n",
    "            for _ in range(5):  # Repeat 5 times\n",
    "                system_message = {\n",
    "                    'role': 'system',\n",
    "                    'content': \"당신은 금융 뉴스 기사에서 감정을 평가하는 주식 분석가입니다.\"\n",
    "                }\n",
    "                question = f\"'{row['Title']}' 제목의 {row['Company']}에 대한 톤이 긍정적, 부정적 또는 중립적인지 결정하십시오.\\n\" \\\n",
    "                           \"다음 형식으로 응답해 주세요. 이유는 생략합니다:\\n\" \\\n",
    "                           \"Sentiment: [긍정/부정/중립]\"\n",
    "                response = ollama.chat(model=model_name, messages=[\n",
    "                    system_message,\n",
    "                    {'role': 'user', 'content': question},\n",
    "                ])\n",
    "                sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"중립\"\n",
    "                extracted_sentiment = extract_sentiment(sentiment_response)\n",
    "                sentiments.append(extracted_sentiment)\n",
    "\n",
    "            # Determine final sentiment based on majority vote\n",
    "            final_sentiment = majority_vote(sentiments)\n",
    "            news_data.at[index, 'Predict'] = final_sentiment\n",
    "\n",
    "            # Save after each prediction\n",
    "            news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d47ca3c-f595-4055-adc5-f5ba467c9a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff9120c79904545acfffc430cecae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/372 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce362d034f1147bf980e1d4a83f26cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/143k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10574f95fcf94d2398fedc12f6fc437a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02813773ae748eab143494a54dbe6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8663f1f4a4a148319442aad26423bc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/881 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206cf5e9cdc34b36b9799bd1ddd460b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/406M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: KR-FinBERT 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/KRFinBERT.csv'에 저장되었습니다.\n",
      "모든 데이터에 대해 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# KR-FinBERT 모델 초기화\n",
    "kr_finbert_model_name = \"snunlp/KR-FinBert-SC\"  # KR-FinBERT 모델 이름 (Hugging Face에 제공된 모델)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kr_finbert_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(kr_finbert_model_name, num_labels=3)\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "# 점수를 감정 레이블로 매핑\n",
    "def map_label_to_sentiment(scores):\n",
    "    labels = [\"부정\", \"중립\", \"긍정\"]\n",
    "    max_index = scores.index(max(scores))\n",
    "    return labels[max_index]\n",
    "\n",
    "# 감정 분석 수행\n",
    "output_csv = os.path.join(output_folder, 'KRFinBERT.csv')\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "else:\n",
    "    news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "    news_data['Predict'] = None\n",
    "\n",
    "for index, row in news_data.iterrows():\n",
    "    if pd.isna(row['Predict']):  # 감정 분석 결과가 없는 경우\n",
    "        text_to_analyze = row['Title']  # Title만 분석\n",
    "        response = sentiment_pipeline(text_to_analyze)[0]  # 각 감정 점수 반환\n",
    "        scores = [score['score'] for score in response]\n",
    "        sentiment = map_label_to_sentiment(scores)\n",
    "\n",
    "        # 감정 분석 결과 저장\n",
    "        news_data.at[index, 'Predict'] = sentiment\n",
    "\n",
    "        # CSV에 저장\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 데이터에 대해 감정 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "184fc588-847e-4702-8fd3-24f2018c7f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ./kb-albert-char-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 성공\n",
      "기존 CSV 파일 로드 성공\n",
      "결과 저장 완료: Sentiment/KBAlbert.csv\n",
      "메시지 전송 성공: KB-ALBERT 모델로 Title 기반 감정 분석이 완료되었습니다. 파일은 'Sentiment/KBAlbert.csv'에 저장되었습니다.\n",
      "모든 데이터에 대해 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "model_folder = './kb-albert-char-base-v2'  # 로컬 모델 폴더 경로\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# kb-albert-char-base-v2 모델 초기화 (로컬 폴더 사용)\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_folder)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_folder, num_labels=3)\n",
    "    sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "    print(\"모델 로드 성공\")\n",
    "except Exception as e:\n",
    "    print(f\"모델 로드 실패: {e}\")\n",
    "    raise e\n",
    "\n",
    "# 점수를 감정 레이블로 매핑\n",
    "def map_label_to_sentiment(scores):\n",
    "    # LABEL 순서: 긍정, 중립, 부정\n",
    "    labels = [\"긍정\", \"중립\", \"부정\"]\n",
    "    max_index = scores.index(max(scores))  # 가장 높은 점수의 인덱스를 찾음\n",
    "    return labels[max_index]\n",
    "\n",
    "# 감정 분석 수행\n",
    "output_csv = os.path.join(output_folder, 'KBAlbert.csv')\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "    print(\"기존 CSV 파일 로드 성공\")\n",
    "else:\n",
    "    news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "    news_data['Predict'] = None  # Predict 열 추가\n",
    "    print(\"새 CSV 파일 로드 성공\")\n",
    "\n",
    "try:\n",
    "    for index, row in news_data.iterrows():\n",
    "        if pd.isna(row['Predict']):  # 감정 분석 결과가 없는 경우\n",
    "            text_to_analyze = row['Title']  # Title 열 분석\n",
    "            response = sentiment_pipeline(text_to_analyze)[0]  # 감정 점수 반환\n",
    "            scores = [score['score'] for score in response]\n",
    "            sentiment = map_label_to_sentiment(scores)  # 감정을 레이블로 매핑\n",
    "\n",
    "            # 감정 분석 결과 저장\n",
    "            news_data.at[index, 'Predict'] = sentiment\n",
    "\n",
    "            # 중간 결과 저장 (주기적으로 저장)\n",
    "            if index % 10 == 0:  # 10개 단위로 저장\n",
    "                news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 최종 결과 저장\n",
    "    news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"결과 저장 완료: {output_csv}\")\n",
    "except Exception as e:\n",
    "    print(f\"감정 분석 도중 에러 발생: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"모든 데이터에 대해 감정 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce84cbcb-7551-43cc-a5d7-7b5a22fffbf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: KcBERT 모델의 감정 분석이 완료되었습니다. 파일은 'Sentiment/KCBERT.csv'에 저장되었습니다.\n",
      "모든 데이터에 대해 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "input_csv = os.path.join(data_folder, 'news_data.csv')\n",
    "\n",
    "# KcBERT 모델 초기화\n",
    "kcbert_model_name = \"beomi/kcbert-base\"  # KcBERT 모델 이름 (Hugging Face에 제공된 모델)\n",
    "tokenizer = AutoTokenizer.from_pretrained(kcbert_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(kcbert_model_name, num_labels=3)\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "# 점수를 감정 레이블로 매핑\n",
    "def map_label_to_sentiment(scores):\n",
    "    labels = [\"부정\", \"중립\", \"긍정\"]\n",
    "    max_index = scores.index(max(scores))\n",
    "    return labels[max_index]\n",
    "\n",
    "# 감정 분석 수행\n",
    "output_csv = os.path.join(output_folder, 'KCBERT.csv')\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "else:\n",
    "    news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "    news_data['Predict'] = None\n",
    "\n",
    "for index, row in news_data.iterrows():\n",
    "    if pd.isna(row['Predict']):  # 감정 분석 결과가 없는 경우\n",
    "        text_to_analyze = row['Title']  # Title만 분석\n",
    "        response = sentiment_pipeline(text_to_analyze)  # 각 감정 점수 반환\n",
    "        scores = [score['score'] for score in response[0]]\n",
    "        sentiment = map_label_to_sentiment(scores)\n",
    "\n",
    "        # 감정 분석 결과 저장\n",
    "        news_data.at[index, 'Predict'] = sentiment\n",
    "\n",
    "        # CSV에 저장\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 데이터에 대해 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4765bb4-14f8-4a76-9347-47e9b0a6aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_KCBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_KRFinBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 KBAlbert 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_KBAlbert-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: gemma2:27b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/gemma2_27b_KCBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: gemma2:27b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/gemma2_27b_KRFinBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: gemma2:27b 모델의 감정 분석이 KBAlbert 참조 기반으로 완료되었습니다. 파일은 'Sentiment/gemma2_27b_KBAlbert-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/mistral_7b_KCBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/mistral_7b_KRFinBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 KBAlbert 참조 기반으로 완료되었습니다. 파일은 'Sentiment/mistral_7b_KBAlbert-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_KCBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_KRFinBERT-ICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 KBAlbert 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_KBAlbert-ICL.csv'에 저장되었습니다.\n",
      "모든 모델의 감정 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 참조 모델 리스트\n",
    "reference_models = [\"KCBERT\", \"KRFinBERT\", \"KBAlbert\"]\n",
    "\n",
    "# Ollama API를 사용하여 모델 이름 리스트 가져오기\n",
    "models_data = ollama.list()\n",
    "models = [model['name'] for model in models_data['models']]  # 모델 이름 추출\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    keywords = [\"긍정\", \"부정\", \"중립\"]\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    return \"중립\"\n",
    "\n",
    "# 각 모델 및 참조 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    \n",
    "    for ref_model in reference_models:\n",
    "        # 참조 모델 데이터 파일 경로\n",
    "        reference_file = os.path.join(data_folder, f'{ref_model}.csv')\n",
    "        \n",
    "        # 참조 모델 데이터 로드\n",
    "        if os.path.exists(reference_file):\n",
    "            ref_df = pd.read_csv(reference_file, encoding='utf-8-sig')\n",
    "        else:\n",
    "            ref_df = pd.DataFrame(columns=['Title', 'Predict'])  # 빈 데이터프레임 초기화\n",
    "\n",
    "        # 모델별, 참조 모델별 CSV 파일 경로 설정\n",
    "        output_csv = os.path.join(output_folder, f'{sanitized_model_name}_{ref_model}-ICL.csv')\n",
    "        \n",
    "        # Load or create the DataFrame\n",
    "        if os.path.exists(output_csv):\n",
    "            news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "        else:\n",
    "            news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "            news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "        # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "        for index, row in news_data.iterrows():\n",
    "            if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "                ref_predict = None\n",
    "                ref_row = ref_df[ref_df['Title'] == row['Title']]\n",
    "                if not ref_row.empty:\n",
    "                    ref_predict = ref_row.iloc[0]['Predict']\n",
    "                    \n",
    "                # Define the system message to set the role\n",
    "                system_message = {\n",
    "                    'role': 'system',\n",
    "                    'content': \"당신은 금융 뉴스 기사에서 감정을 평가하는 주식 분석가입니다.\"\n",
    "                }\n",
    "\n",
    "                # Define the question based on the article title and provide the response format\n",
    "                question = f\"'{row['Title']}' 제목의 {row['Company']}에 대한 톤이 긍정적, 부정적 또는 중립적인지 결정하십시오.\\n\" \\\n",
    "                           f\"참고로, {ref_model} 모델의 예측은 {ref_predict}입니다.\\n\" \\\n",
    "                           \"다음 형식으로 응답해 주세요\\n\" \\\n",
    "                           \"Sentiment: [긍정/부정/중립]\\n\" \\\n",
    "                           \"Reason: [참고 모델과 다른 경우 간단한 이유를 작성해 주세요.]\"\n",
    "\n",
    "                # Send the question to the model\n",
    "                response = ollama.chat(model=model_name, messages=[\n",
    "                    system_message,\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': question,\n",
    "                    },\n",
    "                ])\n",
    "\n",
    "                # Extract the response content\n",
    "                sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"No response\"\n",
    "\n",
    "                # Update the sentiment analysis directly in the DataFrame\n",
    "                news_data.at[index, 'Sentiment Analysis'] = sentiment_response\n",
    "\n",
    "                # Save the DataFrame back to CSV after each response\n",
    "                news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        # Apply the sentiment extraction function to create the Predict column\n",
    "        news_data['Predict'] = news_data['Sentiment Analysis'].apply(extract_sentiment)\n",
    "        \n",
    "        # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08530ac-d1d4-4e15-9275-cca0ffa6f84b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_KCBERT-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_KRFinBERT-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.1:8b 모델의 감정 분석이 KBAlbert 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_1_8b_KBAlbert-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/mistral_7b_KCBERT-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/mistral_7b_KRFinBERT-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: mistral:7b 모델의 감정 분석이 KBAlbert 참조 기반으로 완료되었습니다. 파일은 'Sentiment/mistral_7b_KBAlbert-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 KCBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_KCBERT-BOOTICL.csv'에 저장되었습니다.\n",
      "메시지 전송 성공: llama3.2:3b 모델의 감정 분석이 KRFinBERT 참조 기반으로 완료되었습니다. 파일은 'Sentiment/llama3_2_3b_KRFinBERT-BOOTICL.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ollama\n",
    "from collections import Counter\n",
    "\n",
    "# 폴더 경로 설정\n",
    "data_folder = 'Data'\n",
    "output_folder = 'Sentiment'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 참조 모델 리스트\n",
    "reference_models = [\"KCBERT\", \"KRFinBERT\", \"KBAlbert\"]\n",
    "\n",
    "# Ollama API를 사용하여 모델 이름 리스트 가져오기\n",
    "models = ['llama3.1:8b', 'mistral:7b', 'llama3.2:3b', 'gemma2:27b']\n",
    "\n",
    "def extract_sentiment(text):\n",
    "    keywords = [\"긍정\", \"부정\", \"중립\"]\n",
    "    text = str(text).lower()\n",
    "    indices = {keyword: text.find(keyword) for keyword in keywords}\n",
    "    earliest = min((index for index in indices.values() if index != -1), default=-1)\n",
    "    for keyword, index in indices.items():\n",
    "        if index == earliest:\n",
    "            return keyword\n",
    "    return \"중립\"\n",
    "\n",
    "# 각 모델 및 참조 모델에 대해 sentiment 분석 수행\n",
    "for model_name in models:\n",
    "    sanitized_model_name = re.sub(r'[^a-zA-Z0-9_-]', '_', model_name)\n",
    "    \n",
    "    for ref_model in reference_models:\n",
    "        # 참조 모델 데이터 파일 경로\n",
    "        reference_file = os.path.join(data_folder, f'{ref_model}.csv')\n",
    "        \n",
    "        # 참조 모델 데이터 로드\n",
    "        if os.path.exists(reference_file):\n",
    "            ref_df = pd.read_csv(reference_file, encoding='utf-8-sig')\n",
    "        else:\n",
    "            ref_df = pd.DataFrame(columns=['Title', 'Predict'])  # 빈 데이터프레임 초기화\n",
    "\n",
    "        # 모델별, 참조 모델별 CSV 파일 경로 설정\n",
    "        output_csv = os.path.join(output_folder, f'{sanitized_model_name}_{ref_model}-BOOTICL.csv')\n",
    "        \n",
    "        # Load or create the DataFrame\n",
    "        if os.path.exists(output_csv):\n",
    "            news_data = pd.read_csv(output_csv, encoding='utf-8-sig')\n",
    "        else:\n",
    "            news_data = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "            news_data['Sentiment Analysis'] = None  # Initialize with None for new column\n",
    "\n",
    "        # Loop through each article and ask for sentiment analysis only if 'Sentiment Analysis' is empty\n",
    "        for index, row in news_data.iterrows():\n",
    "            if pd.isna(row['Sentiment Analysis']):  # Check if the sentiment analysis is missing\n",
    "                sentiments = []\n",
    "                for _ in range(5):  # 5회 반복\n",
    "                    ref_predict = None\n",
    "                    ref_row = ref_df[ref_df['Title'] == row['Title']]\n",
    "                    if not ref_row.empty:\n",
    "                        ref_predict = ref_row.iloc[0]['Predict']\n",
    "                    \n",
    "                    # Define the system message to set the role\n",
    "                    system_message = {\n",
    "                        'role': 'system',\n",
    "                        'content': \"당신은 금융 뉴스 기사에서 감정을 평가하는 주식 분석가입니다.\"\n",
    "                    }\n",
    "\n",
    "                    # Define the question based on the article title and provide the response format\n",
    "                    question = f\"'{row['Title']}' 제목의 {row['Company']}에 대한 톤이 긍정적, 부정적 또는 중립적인지 결정하십시오.\\n\" \\\n",
    "                               f\"참고로, {ref_model} 모델의 예측은 {ref_predict}입니다.\\n\" \\\n",
    "                               \"다음 형식으로 응답해 주세요\\n\" \\\n",
    "                               \"Sentiment: [긍정/부정/중립]\"\n",
    "\n",
    "                    # Send the question to the model\n",
    "                    response = ollama.chat(model=model_name, messages=[\n",
    "                        system_message,\n",
    "                        {\n",
    "                            'role': 'user',\n",
    "                            'content': question,\n",
    "                        },\n",
    "                    ])\n",
    "\n",
    "                    # Extract the response content\n",
    "                    sentiment_response = response['message']['content'] if 'message' in response and 'content' in response['message'] else \"중립\"\n",
    "                    sentiment = extract_sentiment(sentiment_response)\n",
    "                    sentiments.append(sentiment)\n",
    "\n",
    "                # Majority voting for sentiment\n",
    "                sentiment_count = Counter(sentiments)\n",
    "                majority_sentiment, count = sentiment_count.most_common(1)[0]\n",
    "                final_sentiment = majority_sentiment if count >= 3 else \"중립\"\n",
    "\n",
    "                # Update the sentiment analysis directly in the DataFrame\n",
    "                news_data.at[index, 'Sentiment Analysis'] = final_sentiment\n",
    "\n",
    "                # Save the DataFrame back to CSV after each response\n",
    "                news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        # Apply the sentiment extraction function to create the Predict column\n",
    "        news_data['Predict'] = news_data['Sentiment Analysis']\n",
    "        \n",
    "        # Save the updated DataFrame with the Predict column back to the CSV file\n",
    "        news_data.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"모든 모델의 감정 분석이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa966e37-6cf4-40dc-81b1-6e48d10ed80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
